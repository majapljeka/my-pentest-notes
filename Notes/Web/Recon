dirsearch -u http://<domainame>

python3 -c 'import pty;pty.spawn("/bin/bash")'   --> interactive terminal

PASSIVE INFO GATHERING:
C:\> whois.exe facebook.com
whois www.example.com

whois x.x.x.x
DNS
Querying: A Records
nslookup example.com
dig facebook.com @1.1.1.1 (Server from previous query)

Querying: A Records for a Subdomain
nslookup -query=A example.com
dig a www.example.com @1.1.1.1

Querying: PTR Records for an IP Address
nslookup -query=PTR 31.13.92.36(facebook address)
dig -x 31.13.92.36 @1.1.1.1

 Querying: ANY Existing Records
 nslookup -query=ANY example.com
 dig any google.com @8.8.8.8
 dig any cloudflare.com @8.8.8.8

 Querying: TXT Records
 nslookup -query=TXT example.com
 dig txt facebook.com @1.1.1.1

 Querying: MX Records
 nslookup -query=MX example.com
 dig mx facebook.com @1.1.1.1

 1. Identifying Nameservers
 nslookup -type=NS zonetransfer.me
 2.Perform the Zone transfer using -type=any and -query=AXFR parameters
 nslookup -type=any -query=AXFR zonetransfer.me nsztm1.digi.ninja

**Passive Subdomain Enumeration**

 Certificates:
    https://censys.io
    https://crt.sh
 https://www.virustotal.com/gui/home/url

 Certificate Transparency:
 export TARGET="facebook.com"
 curl -s "https://crt.sh/?q=${TARGET}&output=json" | jq -r '.[] | "\(.name_value)\n\(.common_name)"' | sort -u > "${TARGET}_crt.sh.txt"
 description: jq -r '.[]' "\(.name_value)\n\(.common_name)"' 	Process the json output and print certificate's name value and common name one per line.
 head -n20 facebook.com_crt.sh.txt

 export TARGET="facebook.com"
 export PORT="443"
 openssl s_client -ign_eof 2>/dev/null <<<$'HEAD / HTTP/1.0\r\n\r' -connect "${TARGET}:${PORT}" | openssl x509 -noout -text -in - | grep 'DNS' | sed -e 's|DNS:|\n|g' -e 's|^\*.*||g' | tr -d ',' | sort -u

 **Automating Passive Subdomain Enumeration**
1. cat sources.txt
baidu
bufferoverun
crtsh
hackertarget
otx
projectdiscovery
rapiddns
sublist3r
threatcrowd
trello
urlscan
vhost
virustotal
zoomeye

2. sasa$ export TARGET="facebook.com"
3. cat sources.txt | while read source; do theHarvester -d "${TARGET}" -b $source -f "${source}_${TARGET}";done
4. When the process finishes, we can extract all the subdomains found and sort them via the following command:
cat *.json | jq -r '.hosts[]' 2>/dev/null | cut -d':' -f 1 | sort -u > "${TARGET}_theHarvester.txt"
5. cat facebook.com_*.txt | sort -u > facebook.com_subdomains_passive.txt
6. cat facebook.com_subdomains_passive.txt | wc -l


**Passive Infrastructure Identification**
https://sitereport.netcraft.com/
https://web.archive.org/

go install github.com/tomnomnom/waybackurls@latest
waybackurls -dates https://facebook.com > waybackurls.txt
cat waybackurls.txt

**Active Infrastructure Identification**
curl -I "http://domain.com" 
curl -I http://domain.com

whatweb -a3 https://www.facebook.com -v

wafw00f -v https://www.tesla.com

**Active Subdomain Enumeration**
https://hackertarget.com/zone-transfer/
